2024-09-07 18:46:18,284 - sqlalchemy.engine.Engine - INFO - [cached since 0.1079s ago] ('Traveled to field sites to as Lead Engineer for deployment, migration and desktop refreshes to new network. Maintained IT hardware and peripheral inv ... (1113 characters truncated) ...  Administered Symantec VERITAS Backup Exec to make sure backups are successful and change tapes. Installed and configured Windows Server 2003 & 2008.', 41, 9)
2024-09-07 18:46:18,288 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 18:46:18,288 - sqlalchemy.engine.Engine - INFO - COMMIT
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 30.83it/s]
2024-09-07 18:46:18,335 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 18:46:18,335 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 18:46:18,336 INFO sqlalchemy.engine.Engine INSERT INTO chunks (content, embedding_id, resume_id) VALUES (?, ?, ?)
2024-09-07 18:46:18,336 - sqlalchemy.engine.Engine - INFO - INSERT INTO chunks (content, embedding_id, resume_id) VALUES (?, ?, ?)
2024-09-07 18:46:18,336 INFO sqlalchemy.engine.Engine [cached since 0.1594s ago] ('Administer Blackberry Exchange Servers; Reset passwords, wipe blackberry data. Installed Blackberry software and setup Blackberry phones and IPADS fo ... (1123 characters truncated) ... dows and different versions of Linux such as Fedora, Ubuntu, CentOS, and Red Hat. Setup cables, server racks, router and switches in the data center.', 42, 9)
2024-09-07 18:46:18,336 - sqlalchemy.engine.Engine - INFO - [cached since 0.1594s ago] ('Administer Blackberry Exchange Servers; Reset passwords, wipe blackberry data. Installed Blackberry software and setup Blackberry phones and IPADS fo ... (1123 characters truncated) ... dows and different versions of Linux such as Fedora, Ubuntu, CentOS, and Red Hat. Setup cables, server racks, router and switches in the data center.', 42, 9)
2024-09-07 18:46:18,338 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 18:46:18,338 - sqlalchemy.engine.Engine - INFO - COMMIT
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 29.55it/s]
2024-09-07 18:46:18,386 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 18:46:18,386 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 18:46:18,386 INFO sqlalchemy.engine.Engine INSERT INTO chunks (content, embedding_id, resume_id) VALUES (?, ?, ?)
2024-09-07 18:46:18,386 - sqlalchemy.engine.Engine - INFO - INSERT INTO chunks (content, embedding_id, resume_id) VALUES (?, ?, ?)
2024-09-07 18:46:18,386 INFO sqlalchemy.engine.Engine [cached since 0.2096s ago] ('Utilize a variety of monitoring tools and network element management systems to triage, troubleshoot and remotely repair problems. October 2007\nto\n ... (1104 characters truncated) ... ne with the business goals. Resolved local IT support for hardware and software problems, including end user desktops, laptops and blackberry phones.', 43, 9)
2024-09-07 18:46:18,386 - sqlalchemy.engine.Engine - INFO - [cached since 0.2096s ago] ('Utilize a variety of monitoring tools and network element management systems to triage, troubleshoot and remotely repair problems. October 2007\nto\n ... (1104 characters truncated) ... ne with the business goals. Resolved local IT support for hardware and software problems, including end user desktops, laptops and blackberry phones.', 43, 9)
2024-09-07 18:46:18,393 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 18:46:18,393 - sqlalchemy.engine.Engine - INFO - COMMIT
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 29.26it/s]
2024-09-07 18:46:18,439 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 18:46:18,439 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 18:46:18,439 INFO sqlalchemy.engine.Engine INSERT INTO chunks (content, embedding_id, resume_id) VALUES (?, ?, ?)
2024-09-07 18:46:18,439 - sqlalchemy.engine.Engine - INFO - INSERT INTO chunks (content, embedding_id, resume_id) VALUES (?, ?, ?)
2024-09-07 18:46:18,440 INFO sqlalchemy.engine.Engine [cached since 0.2635s ago] ('Troubleshoot and configured network printers and replace maintenance kits. October 2006\nto\nJune 2007\nCompany Name\n \nCity\n \n, \nState\n \nData  ... (1119 characters truncated) ... r proof read new entries in Access database for accuracy. Deployment, configuration and technical support for desktops and laptops for 100 end users.', 44, 9)
2024-09-07 18:46:18,440 - sqlalchemy.engine.Engine - INFO - [cached since 0.2635s ago] ('Troubleshoot and configured network printers and replace maintenance kits. October 2006\nto\nJune 2007\nCompany Name\n \nCity\n \n, \nState\n \nData  ... (1119 characters truncated) ... r proof read new entries in Access database for accuracy. Deployment, configuration and technical support for desktops and laptops for 100 end users.', 44, 9)
2024-09-07 18:46:18,444 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 18:46:18,444 - sqlalchemy.engine.Engine - INFO - COMMIT
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 31.34it/s]
2024-09-07 18:46:18,488 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 18:46:18,488 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 18:46:18,488 INFO sqlalchemy.engine.Engine INSERT INTO chunks (content, embedding_id, resume_id) VALUES (?, ?, ?)
2024-09-07 18:46:18,488 - sqlalchemy.engine.Engine - INFO - INSERT INTO chunks (content, embedding_id, resume_id) VALUES (?, ?, ?)
2024-09-07 18:46:18,488 INFO sqlalchemy.engine.Engine [cached since 0.312s ago] ('Reviewed reports created by consultants as part as the QA process to maintain a 95% or better score.November 2004\nto\nMay 2005\nCompany Name\n \nCit ... (985 characters truncated) ... n in Network Engineering 10/2014 - Present\nPresentations\nMaintained configuration management, IT procurement and maintenance renewal documentation.', 45, 9)
2024-09-07 18:46:18,488 - sqlalchemy.engine.Engine - INFO - [cached since 0.312s ago] ('Reviewed reports created by consultants as part as the QA process to maintain a 95% or better score.November 2004\nto\nMay 2005\nCompany Name\n \nCit ... (985 characters truncated) ... n in Network Engineering 10/2014 - Present\nPresentations\nMaintained configuration management, IT procurement and maintenance renewal documentation.', 45, 9)
2024-09-07 18:46:18,492 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 18:46:18,492 - sqlalchemy.engine.Engine - INFO - COMMIT
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 45.00it/s]
2024-09-07 18:46:18,528 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 18:46:18,528 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 18:46:18,529 INFO sqlalchemy.engine.Engine INSERT INTO chunks (content, embedding_id, resume_id) VALUES (?, ?, ?)
2024-09-07 18:46:18,529 - sqlalchemy.engine.Engine - INFO - INSERT INTO chunks (content, embedding_id, resume_id) VALUES (?, ?, ?)
2024-09-07 18:46:18,529 INFO sqlalchemy.engine.Engine [cached since 0.3522s ago] ('Created and updated network diagrams using\nMicrosoft Visio to provide for presentations\nCertifications\nNew Horizons Computer Learning Center, Atlanta, GA CompTia A+ and Network Sunset Learning Center Red Hat System Administration I\n(RH124)\nLanguages\nFluent in Spanish.', 46, 9)
2024-09-07 18:46:18,529 - sqlalchemy.engine.Engine - INFO - [cached since 0.3522s ago] ('Created and updated network diagrams using\nMicrosoft Visio to provide for presentations\nCertifications\nNew Horizons Computer Learning Center, Atlanta, GA CompTia A+ and Network Sunset Learning Center Red Hat System Administration I\n(RH124)\nLanguages\nFluent in Spanish.', 46, 9)
2024-09-07 18:46:18,532 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 18:46:18,532 - sqlalchemy.engine.Engine - INFO - COMMIT
Batches: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 26.62it/s]
2024-09-07 18:46:18,603 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 18:46:18,603 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 18:46:18,603 INFO sqlalchemy.engine.Engine INSERT INTO chunks (content, embedding_id, resume_id) VALUES (?, ?, ?)
2024-09-07 18:46:18,603 - sqlalchemy.engine.Engine - INFO - INSERT INTO chunks (content, embedding_id, resume_id) VALUES (?, ?, ?)
2024-09-07 18:46:18,603 INFO sqlalchemy.engine.Engine [cached since 0.4269s ago] ('Skills\nDeployment, Maintenance, Active Directory, Testing, Workstations, Access, Technical Support, Printers, Blackberry, Windows Server 2003,\nCase ... (1194 characters truncated) ... ments, Team Lead, Data\nCenter, Red Hat, Router, File, Helpdesk, Telephone, Apache, Clients, Migrations, Mysql, Php, Solutions, Web Server, Associate', 47, 9)
2024-09-07 18:46:18,603 - sqlalchemy.engine.Engine - INFO - [cached since 0.4269s ago] ('Skills\nDeployment, Maintenance, Active Directory, Testing, Workstations, Access, Technical Support, Printers, Blackberry, Windows Server 2003,\nCase ... (1194 characters truncated) ... ments, Team Lead, Data\nCenter, Red Hat, Router, File, Helpdesk, Telephone, Apache, Clients, Migrations, Mysql, Php, Solutions, Web Server, Associate', 47, 9)
2024-09-07 18:46:18,616 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 18:46:18,616 - sqlalchemy.engine.Engine - INFO - COMMIT
2024-09-07 18:46:18,640 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 18:46:18,640 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 18:46:18,642 INFO sqlalchemy.engine.Engine INSERT INTO faiss_index_data (data) VALUES (?)
2024-09-07 18:46:18,642 - sqlalchemy.engine.Engine - INFO - INSERT INTO faiss_index_data (data) VALUES (?)
2024-09-07 18:46:18,642 INFO sqlalchemy.engine.Engine [generated in 0.00058s] (<memory at 0x7f450b32ea00>,)
2024-09-07 18:46:18,642 - sqlalchemy.engine.Engine - INFO - [generated in 0.00058s] (<memory at 0x7f450b32ea00>,)
2024-09-07 18:46:18,647 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 18:46:18,647 - sqlalchemy.engine.Engine - INFO - COMMIT
2024-09-07 18:46:18,660 - app.services.index_manager - INFO - FAISS index saved to database
2024-09-07 18:46:18,661 - app.services.resume_processor - INFO - Resume cv_test_3.pdf (originally cv_test_3.pdf) processed and stored successfully
INFO:     127.0.0.1:49696 - "POST /resumes/ HTTP/1.1" 200 OK
2024-09-07 18:47:27,098 - app.services.llm - INFO - Initializing LLM with model: meta-llama/Meta-Llama-3.1-8B-Instruct
tokenizer_config.json: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 55.4k/55.4k [00:00<00:00, 750kB/s]
tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 9.09M/9.09M [00:03<00:00, 2.44MB/s]
special_tokens_map.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 296/296 [00:00<00:00, 288kB/s]
config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 855/855 [00:00<00:00, 601kB/s]
model.safetensors.index.json: 100%|███████████████████████████████████████████████████████████████████████████████████████| 23.9k/23.9k [00:00<00:00, 7.81MB/s]
model-00001-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████| 4.98G/4.98G [24:12<00:00, 3.43MB/s]
model-00002-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████| 5.00G/5.00G [26:19<00:00, 3.17MB/s]
model-00003-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████| 4.92G/4.92G [24:09<00:00, 3.39MB/s]
model-00004-of-00004.safetensors: 100%|███████████████████████████████████████████████████████████████████████████████████| 1.17G/1.17G [05:44<00:00, 3.39MB/s]
Downloading shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [1:20:28<00:00, 1207.13s/it]
Loading checkpoint shards:  25%|████████████████████████▎                                                                        | 1/4 [00:40<02:00, 40.31s/it]
WARNING:  StatReload detected changes in 'app/download_model.py'. Reloading...
WARNING:  StatReload detected changes in 'app/download_model.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
INFO:     Started server process [57389]
INFO:     Waiting for application startup.
2024-09-07 21:29:01,716 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 21:29:01,716 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 21:29:01,716 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("resumes")
2024-09-07 21:29:01,716 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("resumes")
2024-09-07 21:29:01,716 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:29:01,716 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:29:01,719 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("chunks")
2024-09-07 21:29:01,719 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("chunks")
2024-09-07 21:29:01,719 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:29:01,719 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:29:01,720 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:29:01,720 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:29:01,720 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:29:01,720 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:29:01,722 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 21:29:01,722 - sqlalchemy.engine.Engine - INFO - COMMIT
INFO:     Application startup complete.
WARNING:  StatReload detected changes in 'app/main.py'. Reloading...
INFO:     Shutting down
INFO:     Waiting for application shutdown.
2024-09-07 21:32:28,733 - app.main - INFO - Conversation history cleared on shutdown.
INFO:     Application shutdown complete.
INFO:     Finished server process [57389]
WARNING:  StatReload detected changes in 'app/main.py'. Reloading...
WARNING:  StatReload detected changes in 'app/main.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
INFO:     Started server process [58014]
INFO:     Waiting for application startup.
2024-09-07 21:32:38,193 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 21:32:38,193 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 21:32:38,193 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("resumes")
2024-09-07 21:32:38,193 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("resumes")
2024-09-07 21:32:38,193 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:32:38,193 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:32:38,195 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("chunks")
2024-09-07 21:32:38,195 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("chunks")
2024-09-07 21:32:38,195 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:32:38,195 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:32:38,196 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:32:38,196 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:32:38,196 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:32:38,196 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:32:38,198 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 21:32:38,198 - sqlalchemy.engine.Engine - INFO - COMMIT
ERROR:    Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 677, in lifespan
    async with self.lifespan_context(app) as maybe_state:
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 566, in __aenter__
    await self._router.startup()
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 654, in startup
    await handler()
  File "/workspaces/resume-matcher/backend/app/main.py", line 63, in startup_event
    get_llm_instance()
NameError: name 'get_llm_instance' is not defined

ERROR:    Application startup failed. Exiting.
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
Process SpawnProcess-118:
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/_subprocess.py", line 76, in subprocess_started
    target(sockets=sockets)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 61, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/local/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 68, in serve
    config.load()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/config.py", line 467, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/workspaces/resume-matcher/backend/app/main.py", line 5, in <module>
    from app.api.chat_endpoint import router as chat_router
  File "/workspaces/resume-matcher/backend/app/api/chat_endpoint.py", line 6, in <module>
    from app.containers import Container
  File "/workspaces/resume-matcher/backend/app/containers.py", line 2, in <module>
    from app.services.llm import LLM
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 14
    def __new__(cls):
                     ^
IndentationError: unindent does not match any outer indentation level
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
INFO:     Started server process [58256]
INFO:     Waiting for application startup.
2024-09-07 21:33:43,582 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 21:33:43,582 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 21:33:43,583 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("resumes")
2024-09-07 21:33:43,583 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("resumes")
2024-09-07 21:33:43,583 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:33:43,583 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:33:43,584 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("chunks")
2024-09-07 21:33:43,584 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("chunks")
2024-09-07 21:33:43,584 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:33:43,584 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:33:43,585 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:33:43,585 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:33:43,585 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:33:43,585 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:33:43,587 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 21:33:43,587 - sqlalchemy.engine.Engine - INFO - COMMIT
ERROR:    Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 677, in lifespan
    async with self.lifespan_context(app) as maybe_state:
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 566, in __aenter__
    await self._router.startup()
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 654, in startup
    await handler()
  File "/workspaces/resume-matcher/backend/app/main.py", line 63, in startup_event
    get_llm_instance()
NameError: name 'get_llm_instance' is not defined

ERROR:    Application startup failed. Exiting.
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
Process SpawnProcess-120:
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/_subprocess.py", line 76, in subprocess_started
    target(sockets=sockets)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 61, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/local/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 68, in serve
    config.load()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/config.py", line 467, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/workspaces/resume-matcher/backend/app/main.py", line 5, in <module>
    from app.api.chat_endpoint import router as chat_router
  File "/workspaces/resume-matcher/backend/app/api/chat_endpoint.py", line 6, in <module>
    from app.containers import Container
  File "/workspaces/resume-matcher/backend/app/containers.py", line 2, in <module>
    from app.services.llm import LLM
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 22
    cache_dir = "/app/model_cache"
                                  ^
IndentationError: unindent does not match any outer indentation level
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
INFO:     Started server process [58395]
INFO:     Waiting for application startup.
2024-09-07 21:34:05,637 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 21:34:05,637 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 21:34:05,637 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("resumes")
2024-09-07 21:34:05,637 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("resumes")
2024-09-07 21:34:05,637 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:34:05,637 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:34:05,639 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("chunks")
2024-09-07 21:34:05,639 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("chunks")
2024-09-07 21:34:05,639 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:34:05,639 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:34:05,640 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:34:05,640 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:34:05,640 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:34:05,640 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:34:05,641 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 21:34:05,641 - sqlalchemy.engine.Engine - INFO - COMMIT
ERROR:    Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 677, in lifespan
    async with self.lifespan_context(app) as maybe_state:
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 566, in __aenter__
    await self._router.startup()
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 654, in startup
    await handler()
  File "/workspaces/resume-matcher/backend/app/main.py", line 63, in startup_event
    get_llm_instance()
NameError: name 'get_llm_instance' is not defined

ERROR:    Application startup failed. Exiting.
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
INFO:     Started server process [58477]
INFO:     Waiting for application startup.
2024-09-07 21:34:17,750 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 21:34:17,750 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 21:34:17,751 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("resumes")
2024-09-07 21:34:17,751 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("resumes")
2024-09-07 21:34:17,751 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:34:17,751 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:34:17,752 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("chunks")
2024-09-07 21:34:17,752 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("chunks")
2024-09-07 21:34:17,752 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:34:17,752 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:34:17,754 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:34:17,754 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:34:17,754 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:34:17,754 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:34:17,755 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 21:34:17,755 - sqlalchemy.engine.Engine - INFO - COMMIT
ERROR:    Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 677, in lifespan
    async with self.lifespan_context(app) as maybe_state:
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 566, in __aenter__
    await self._router.startup()
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 654, in startup
    await handler()
  File "/workspaces/resume-matcher/backend/app/main.py", line 63, in startup_event
    get_llm_instance()
NameError: name 'get_llm_instance' is not defined

ERROR:    Application startup failed. Exiting.
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
INFO:     Started server process [58600]
INFO:     Waiting for application startup.
2024-09-07 21:34:33,331 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 21:34:33,331 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 21:34:33,331 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("resumes")
2024-09-07 21:34:33,331 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("resumes")
2024-09-07 21:34:33,331 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:34:33,331 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:34:33,334 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("chunks")
2024-09-07 21:34:33,334 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("chunks")
2024-09-07 21:34:33,334 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:34:33,334 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:34:33,335 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:34:33,335 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:34:33,335 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:34:33,335 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:34:33,337 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 21:34:33,337 - sqlalchemy.engine.Engine - INFO - COMMIT
ERROR:    Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 677, in lifespan
    async with self.lifespan_context(app) as maybe_state:
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 566, in __aenter__
    await self._router.startup()
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 654, in startup
    await handler()
  File "/workspaces/resume-matcher/backend/app/main.py", line 63, in startup_event
    get_llm_instance()
NameError: name 'get_llm_instance' is not defined

ERROR:    Application startup failed. Exiting.
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
INFO:     Started server process [58715]
INFO:     Waiting for application startup.
2024-09-07 21:34:57,676 INFO sqlalchemy.engine.Engine BEGIN (implicit)
2024-09-07 21:34:57,676 - sqlalchemy.engine.Engine - INFO - BEGIN (implicit)
2024-09-07 21:34:57,677 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("resumes")
2024-09-07 21:34:57,677 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("resumes")
2024-09-07 21:34:57,677 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:34:57,677 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:34:57,678 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("chunks")
2024-09-07 21:34:57,678 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("chunks")
2024-09-07 21:34:57,678 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:34:57,678 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:34:57,679 INFO sqlalchemy.engine.Engine PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:34:57,679 - sqlalchemy.engine.Engine - INFO - PRAGMA main.table_info("faiss_index_data")
2024-09-07 21:34:57,679 INFO sqlalchemy.engine.Engine [raw sql] ()
2024-09-07 21:34:57,679 - sqlalchemy.engine.Engine - INFO - [raw sql] ()
2024-09-07 21:34:57,681 INFO sqlalchemy.engine.Engine COMMIT
2024-09-07 21:34:57,681 - sqlalchemy.engine.Engine - INFO - COMMIT
ERROR:    Traceback (most recent call last):
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 677, in lifespan
    async with self.lifespan_context(app) as maybe_state:
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 566, in __aenter__
    await self._router.startup()
  File "/usr/local/lib/python3.9/site-packages/starlette/routing.py", line 654, in startup
    await handler()
  File "/workspaces/resume-matcher/backend/app/main.py", line 63, in startup_event
    get_llm_instance()
NameError: name 'get_llm_instance' is not defined

ERROR:    Application startup failed. Exiting.
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
Process SpawnProcess-128:
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/_subprocess.py", line 76, in subprocess_started
    target(sockets=sockets)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 61, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/local/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 68, in serve
    config.load()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/config.py", line 467, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/workspaces/resume-matcher/backend/app/main.py", line 5, in <module>
    from app.api.chat_endpoint import router as chat_router
  File "/workspaces/resume-matcher/backend/app/api/chat_endpoint.py", line 6, in <module>
    from app.containers import Container
  File "/workspaces/resume-matcher/backend/app/containers.py", line 2, in <module>
    from app.services.llm import LLM
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 110, in <module>
    llm_instance = LLM()
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 17, in __new__
    cls._instance.initialize()
AttributeError: 'LLM' object has no attribute 'initialize'
WARNING:  StatReload detected changes in 'app/main.py'. Reloading...
WARNING:  StatReload detected changes in 'app/main.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
Process SpawnProcess-130:
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/_subprocess.py", line 76, in subprocess_started
    target(sockets=sockets)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 61, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/local/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 68, in serve
    config.load()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/config.py", line 467, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/workspaces/resume-matcher/backend/app/main.py", line 2, in <module>
    from app.services.llm import get_llm_instance
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 110, in <module>
    llm_instance = LLM()
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 17, in __new__
    cls._instance.initialize()
AttributeError: 'LLM' object has no attribute 'initialize'
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
tokenizer_config.json: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 55.4k/55.4k [00:00<00:00, 1.24MB/s]
tokenizer.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████| 9.09M/9.09M [00:02<00:00, 3.16MB/s]
special_tokens_map.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 296/296 [00:00<00:00, 116kB/s]
config.json: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 855/855 [00:00<00:00, 310kB/s]
Process SpawnProcess-131:
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/_subprocess.py", line 76, in subprocess_started
    target(sockets=sockets)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 61, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/local/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 68, in serve
    config.load()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/config.py", line 467, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/workspaces/resume-matcher/backend/app/main.py", line 2, in <module>
    from app.services.llm import get_llm_instance
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 110, in <module>
    llm_instance = LLM()
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 17, in __new__
    cls._instance.__init__()
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 24, in __init__
    self.model = AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3318, in from_pretrained
    raise ImportError(
ImportError: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
Process SpawnProcess-133:
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/_subprocess.py", line 76, in subprocess_started
    target(sockets=sockets)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 61, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/local/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 68, in serve
    config.load()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/config.py", line 467, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/workspaces/resume-matcher/backend/app/main.py", line 2, in <module>
    from app.services.llm import get_llm_instance
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 110, in <module>
    llm_instance = LLM()
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 17, in __new__
    cls._instance.__init__()
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 24, in __init__
    self.model = AutoModelForCausalLM.from_pretrained(
  File "/usr/local/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 564, in from_pretrained
    return model_class.from_pretrained(
  File "/usr/local/lib/python3.9/site-packages/transformers/modeling_utils.py", line 3318, in from_pretrained
    raise ImportError(
ImportError: Using `low_cpu_mem_usage=True` or a `device_map` requires Accelerate: `pip install accelerate`
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
Process SpawnProcess-134:
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/_subprocess.py", line 76, in subprocess_started
    target(sockets=sockets)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 61, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/local/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 68, in serve
    config.load()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/config.py", line 467, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/workspaces/resume-matcher/backend/app/main.py", line 2, in <module>
    from app.services.llm import get_llm_instance
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 122, in <module>
    llm_instance = LLM()
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 17, in __new__
    cls._instance.__init__()
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 26, in __init__
    with init_empty_weights():
NameError: name 'init_empty_weights' is not defined
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
Process SpawnProcess-135:
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/_subprocess.py", line 76, in subprocess_started
    target(sockets=sockets)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 61, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/local/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 68, in serve
    config.load()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/config.py", line 467, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/workspaces/resume-matcher/backend/app/main.py", line 2, in <module>
    from app.services.llm import get_llm_instance
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 122, in <module>
    llm_instance = LLM()
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 17, in __new__
    cls._instance.__init__()
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 26, in __init__
    with init_empty_weights():
NameError: name 'init_empty_weights' is not defined
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
Process SpawnProcess-137:
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/_subprocess.py", line 76, in subprocess_started
    target(sockets=sockets)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 61, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/local/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 68, in serve
    config.load()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/config.py", line 467, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/workspaces/resume-matcher/backend/app/main.py", line 2, in <module>
    from app.services.llm import get_llm_instance
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 7, in <module>
    from accelerate import init_empty_weights, load_checkpoint_and_dispatch
ModuleNotFoundError: No module named 'accelerate'
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
Process SpawnProcess-139:
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/_subprocess.py", line 76, in subprocess_started
    target(sockets=sockets)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 61, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/local/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 68, in serve
    config.load()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/config.py", line 467, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/workspaces/resume-matcher/backend/app/main.py", line 2, in <module>
    from app.services.llm import get_llm_instance
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 7, in <module>
    from accelerate import init_empty_weights, load_checkpoint_and_dispatch
ModuleNotFoundError: No module named 'accelerate'
WARNING:  StatReload detected changes in 'app/services/llm.py'. Reloading...
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
Process SpawnProcess-140:
Traceback (most recent call last):
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 315, in _bootstrap
    self.run()
  File "/usr/local/lib/python3.9/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/_subprocess.py", line 76, in subprocess_started
    target(sockets=sockets)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 61, in run
    return asyncio.run(self.serve(sockets=sockets))
  File "/usr/local/lib/python3.9/asyncio/runners.py", line 44, in run
    return loop.run_until_complete(main)
  File "/usr/local/lib/python3.9/asyncio/base_events.py", line 647, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/server.py", line 68, in serve
    config.load()
  File "/usr/local/lib/python3.9/site-packages/uvicorn/config.py", line 467, in load
    self.loaded_app = import_from_string(self.app)
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 24, in import_from_string
    raise exc from None
  File "/usr/local/lib/python3.9/site-packages/uvicorn/importer.py", line 21, in import_from_string
    module = importlib.import_module(module_str)
  File "/usr/local/lib/python3.9/importlib/__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1030, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1007, in _find_and_load
  File "<frozen importlib._bootstrap>", line 986, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 680, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/workspaces/resume-matcher/backend/app/main.py", line 2, in <module>
    from app.services.llm import get_llm_instance
  File "/workspaces/resume-matcher/backend/app/services/llm.py", line 7, in <module>
    from accelerate import init_empty_weights, load_checkpoint_and_dispatch
ModuleNotFoundError: No module named 'accelerate'
^CINFO:     Stopping reloader process [818]
root@14156e1a7dcf:/workspaces/resume-matcher/backend# /usr/local/lib/python3.9/multiprocessing/resource_tracker.py:216: UserWarning: resource_tracker: There appear to be 1 leaked semaphore objects to clean up at shutdown
  warnings.warn('resource_tracker: There appear to be %d '
^C
(failed reverse-i-search)`pip': uvicorn app.main:app --reload --host 0.0.0.0 --^Crt 8000
root@14156e1a7dcf:/workspaces/resume-matcher/backend# pip install -r requirements.txt 
Requirement already satisfied: fastapi==0.103.2 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (0.103.2)
Requirement already satisfied: pydantic==2.5.2 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.5.2)
Requirement already satisfied: pydantic-settings==2.1.0 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (2.1.0)
Requirement already satisfied: sqlalchemy==2.0.32 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (2.0.32)
Requirement already satisfied: aiosqlite==0.19.0 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (0.19.0)
Requirement already satisfied: torch==2.0.1 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 13)) (2.0.1)
Requirement already satisfied: sentence-transformers==2.2.2 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 14)) (2.2.2)
Requirement already satisfied: faiss-cpu==1.7.4 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 15)) (1.7.4)
Collecting accelerate==0.22.0
  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 251.2/251.2 kB 1.0 MB/s eta 0:00:00
Requirement already satisfied: PyPDF2==3.0.1 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 19)) (3.0.1)
Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 22)) (3.8.1)
Requirement already satisfied: schedule==1.2.0 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 25)) (1.2.0)
Requirement already satisfied: pytest==6.2.5 in /root/.local/lib/python3.9/site-packages (from -r requirements.txt (line 28)) (6.2.5)
Requirement already satisfied: dependency-injector==4.41.0 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 31)) (4.41.0)
Requirement already satisfied: typing-extensions==4.7.1 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 34)) (4.7.1)
Requirement already satisfied: starlette==0.27.0 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 35)) (0.27.0)
Requirement already satisfied: uvicorn==0.23.2 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 36)) (0.23.2)
Requirement already satisfied: python-multipart==0.0.6 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 37)) (0.0.6)
Requirement already satisfied: numpy==1.24.3 in /usr/local/lib/python3.9/site-packages (from -r requirements.txt (line 40)) (1.24.3)
Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.9/site-packages (from fastapi==0.103.2->-r requirements.txt (line 2)) (3.7.1)
Requirement already satisfied: pydantic-core==2.14.5 in /usr/local/lib/python3.9/site-packages (from pydantic==2.5.2->-r requirements.txt (line 5)) (2.14.5)
Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.9/site-packages (from pydantic==2.5.2->-r requirements.txt (line 5)) (0.7.0)
Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.9/site-packages (from pydantic-settings==2.1.0->-r requirements.txt (line 6)) (1.0.1)
Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/site-packages (from sqlalchemy==2.0.32->-r requirements.txt (line 9)) (3.0.3)
Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (11.7.4.91)
Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (11.7.99)
Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (11.4.0.1)
Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (2.14.3)
Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (11.7.101)
Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (8.5.0.96)
Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (10.9.0.58)
Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (3.1.4)
Requirement already satisfied: sympy in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (1.13.2)
Requirement already satisfied: networkx in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (3.2.1)
Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (11.7.99)
Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (11.7.91)
Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (2.0.0)
Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (11.10.3.66)
Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (10.2.10.91)
Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from torch==2.0.1->-r requirements.txt (line 13)) (3.16.0)
Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.9/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 14)) (0.24.6)
Requirement already satisfied: torchvision in /usr/local/lib/python3.9/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 14)) (0.15.2)
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 14)) (1.5.1)
Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.9/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 14)) (4.44.2)
Requirement already satisfied: tqdm in /usr/local/lib/python3.9/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 14)) (4.66.5)
Requirement already satisfied: scipy in /usr/local/lib/python3.9/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 14)) (1.13.1)
Requirement already satisfied: sentencepiece in /usr/local/lib/python3.9/site-packages (from sentence-transformers==2.2.2->-r requirements.txt (line 14)) (0.2.0)
Collecting psutil
  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)
     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 290.5/290.5 kB 1.9 MB/s eta 0:00:00
Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from accelerate==0.22.0->-r requirements.txt (line 16)) (24.1)
Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/site-packages (from accelerate==0.22.0->-r requirements.txt (line 16)) (6.0.2)
Requirement already satisfied: joblib in /usr/local/lib/python3.9/site-packages (from nltk==3.8.1->-r requirements.txt (line 22)) (1.4.2)
Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/site-packages (from nltk==3.8.1->-r requirements.txt (line 22)) (2024.7.24)
Requirement already satisfied: click in /usr/local/lib/python3.9/site-packages (from nltk==3.8.1->-r requirements.txt (line 22)) (8.1.7)
Requirement already satisfied: toml in /usr/local/lib/python3.9/site-packages (from pytest==6.2.5->-r requirements.txt (line 28)) (0.10.2)
Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.9/site-packages (from pytest==6.2.5->-r requirements.txt (line 28)) (1.5.0)
Requirement already satisfied: py>=1.8.2 in /usr/local/lib/python3.9/site-packages (from pytest==6.2.5->-r requirements.txt (line 28)) (1.11.0)
Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.9/site-packages (from pytest==6.2.5->-r requirements.txt (line 28)) (24.2.0)
Requirement already satisfied: iniconfig in /usr/local/lib/python3.9/site-packages (from pytest==6.2.5->-r requirements.txt (line 28)) (2.0.0)
Requirement already satisfied: six<=1.16.0,>=1.7.0 in /usr/local/lib/python3.9/site-packages (from dependency-injector==4.41.0->-r requirements.txt (line 31)) (1.16.0)
Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.9/site-packages (from uvicorn==0.23.2->-r requirements.txt (line 36)) (0.14.0)
Requirement already satisfied: wheel in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 13)) (0.44.0)
Requirement already satisfied: setuptools in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->-r requirements.txt (line 13)) (58.1.0)
Requirement already satisfied: lit in /usr/local/lib/python3.9/site-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 13)) (18.1.8)
Requirement already satisfied: cmake in /usr/local/lib/python3.9/site-packages (from triton==2.0.0->torch==2.0.1->-r requirements.txt (line 13)) (3.30.2)
Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.9/site-packages (from anyio<4.0.0,>=3.7.1->fastapi==0.103.2->-r requirements.txt (line 2)) (1.3.1)
Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.9/site-packages (from anyio<4.0.0,>=3.7.1->fastapi==0.103.2->-r requirements.txt (line 2)) (3.8)
Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.9/site-packages (from anyio<4.0.0,>=3.7.1->fastapi==0.103.2->-r requirements.txt (line 2)) (1.2.2)
Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (2.32.3)
Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (2024.9.0)
Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (0.4.5)
Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (0.19.1)
Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->torch==2.0.1->-r requirements.txt (line 13)) (2.1.5)
Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (3.5.0)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.9/site-packages (from sympy->torch==2.0.1->-r requirements.txt (line 13)) (1.3.0)
Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/site-packages (from torchvision->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (10.4.0)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (2024.8.30)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (2.2.2)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers==2.2.2->-r requirements.txt (line 14)) (3.3.2)
Installing collected packages: psutil, accelerate
Successfully installed accelerate-0.22.0 psutil-6.0.0
WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv

[notice] A new release of pip is available: 23.0.1 -> 24.2
[notice] To update, run: pip install --upgrade pip
root@14156e1a7dcf:/workspaces/resume-matcher/backend# uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
INFO:     Will watch for changes in these directories: ['/workspaces/resume-matcher/backend']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [61669] using StatReload
{'APP_NAME': 'LLM API', 'DEBUG': False, 'MODEL_NAME': 'meta-llama/Meta-Llama-3.1-8B-Instruct', 'EMBEDDING_MODEL_NAME': 'paraphrase-MiniLM-L6-v2', 'MAX_LENGTH': 200, 'CONTEXT_LENGTH': 2000, 'HOST': '0.0.0.0', 'PORT': 8000, 'VECTOR_DIMENSION': 384, 'CHUNK_SIZE': 200, 'CHUNK_OVERLAP': 0, 'DATABASE_URL': 'sqlite+aiosqlite:///./app/database/resume_data.db', 'TEST_DATABASE_URL': 'sqlite+aiosqlite:///./app/database/test_database.db', 'FAISS_OPTIMIZATION_INTERVAL_HOURS': 24}
The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.
Token is valid (permission: fineGrained).
Your token has been saved to /root/.cache/huggingface/token
Login successful
model.safetensors.index.json: 100%|███████████████████████████████████████████████████████████████████████████████████████| 23.9k/23.9k [00:00<00:00, 3.49MB/s]
Downloading shards:   0%|                                                                                                                | 0/4 [00:00<?, ?it/s]
model-00001-of-00004.safetensors:  13%|███████████▏                                                                       | 671M/4.98G [08:18<1:12:08, 995kB/s]